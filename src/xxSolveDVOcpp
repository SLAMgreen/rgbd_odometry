#include <SolveDVO.h>


/// default constructor. Init the subscribers
SolveDVO::SolveDVO()
{
    // reset all flags
    isFrameAvailable = false;
    isNowFrameAvailable = false;
    isRefFrameAvailable = false;
    isPyramidalRefFrameAvailable = false;
    isPyramidalNowFrameAvailable = false;
    isJacobiansAvailable = false;

    sub = nh.subscribe( "odometry/rgbd", 2, &SolveDVO::imageArrivedCallBack, this );

    pub_pc = nh.advertise<sensor_msgs::PointCloud>( "dvo/pointCloud", 10 );

}


/// Input opencv XML file containing camera internal params and distortion coif.
/// Note: At this moment the distortion coif. are not used.
void SolveDVO::setCameraMatrix(char* calibFile)
{
    //
    // Read calibration matrix, distortion coiffs
    //
    cv::FileStorage fs(calibFile, cv::FileStorage::READ);
    if( fs.isOpened() == false )
    {
        ROS_ERROR_STREAM( "[SolvePnP::setCameraMatrix] Error opening camera "
                "params file : "<< calibFile );
        return;
    }

    fs["cameraMatrix"] >> cameraMatrix;
    fs["distCoeffs"] >> distCoeffs;
    //cout<< "Camera Matrix : \n"<<  cameraMatrix << endl;
    //cout<< "Distortion Coifs : \n"<< distCoeffs << endl;
    fx = cameraMatrix.at<double>(0,0);
    fy = cameraMatrix.at<double>(1,1);
    cx = cameraMatrix.at<double>(0,2);
    cy = cameraMatrix.at<double>(1,2);

    K = Eigen::Matrix3d::Zero();
    K(0,0) = fx;
    K(1,1) = fy;
    K(0,2) = cx;
    K(1,2) = cy;
    K(2,2) = 1.0;

    K_inv = K.inverse();

    ROS_INFO( "[SolvePnP::setCameraMatrix] Camera Matrix & Distortion Coif Loaded");
    ROS_INFO( "fx=%.4f, fy=%.4f, cx=%.4f, cy=%.4f", fx, fy, cx, cy );


    cameraIntrinsicsReady = true;

}


/// @brief Callback to receive RGBD from the topic "odometry/rgbd"
///
/// The subscriber is defined in the construction. This function is the callback for the same.
/// This is a blocking function. Thus do not do any processing here.
/*
void SolveDVO::imageArrivedCallBack( rgbd_odometry::RGBDFrameConstPtr msg )
{
    ROS_INFO_STREAM_ONCE( "1st RGBD frame received. Will continue receiving but not report anymore on this");
    isFrameAvailable=false;


    cv::Mat frame, dframe;

    try
    {
        frame =  cv_bridge::toCvShare(  msg->frame, msg, "bgr8" )->image ;
        dframe =  cv_bridge::toCvShare(  msg->dframe, msg, "mono16" )->image ;
    }
    catch( cv_bridge::Exception& e )
    {
        ROS_ERROR( "cv_bridge exception: %s", e.what() );
        isFrameAvailable = false;
        return;
    }

    dframe.setTo(1, (dframe==0) ); //to avoid zero depth

    //
    // setting up frames in openCV format
    frame.copyTo( this->rcvd_frame );
    dframe.copyTo( this->rcvd_dframe );


    //
    // setting up frames in Eigen format

    // the r, g, b channels
    std::vector<cv::Mat> channels;
    cv::split( frame, channels );

    cv::cv2eigen( channels[0], rcvd_blue );
    cv::cv2eigen( channels[1], rcvd_green );
    cv::cv2eigen( channels[2], rcvd_red );


    // convert to gray scale
    cv::cvtColor( frame, rcvd_grayMat, CV_BGR2GRAY );
    cv::cv2eigen( rcvd_grayMat, rcvd_gray );


    // depth map
    cv::cv2eigen( dframe, rcvd_depth );


    // Pyramidals of `rcvd_grayMat` and `dframe`
    pydRcvdGray.push_back(rcvd_gray);
    pydRcvdDepthMap.push_back(rcvd_depth);
    float scale = 1;
    for( int i=0 ; i<=4 ; i++ )
    {
        scale *= 0.5;

        cv::Mat xtmpgray, xtmpdepth;
        Eigen::MatrixXd xtmpgray_eigen, xtmpdepth_eigen;

        cv::resize(rcvd_grayMat, xtmpgray, cv::Size(), scale, scale, cv::INTER_NEAREST );
        cv::resize(dframe, xtmpdepth, cv::Size(), scale, scale, cv::INTER_NEAREST );

        cv::cv2eigen( xtmpgray, xtmpgray_eigen );
        cv::cv2eigen( xtmpdepth, xtmpdepth_eigen );

        pydRcvdGray.push_back(xtmpgray_eigen);
        pydRcvdDepthMap.push_back(xtmpdepth_eigen);

    }


    isFrameAvailable=true;

}
*/



/// @brief Publishes the point cloud of current RGBD.
/// Uses the current RGBD, camera matrix and creates a point cloud. Note that the coords are in frame of the camera (ie. camera center is the origin)
void SolveDVO::publishCurrentPointCloud()
{
    assert( isFrameAvailable );
    assert( cameraIntrinsicsReady );


    sensor_msgs::PointCloud pcl_msg;
    pcl_msg.header.frame_id = "denseVO";
    pcl_msg.header.stamp = ros::Time::now();
    pcl_msg.header.seq = 0;

    sensor_msgs::ChannelFloat32 shadeR, shadeG, shadeB, shade_gray;
    shadeR.name = "r";
    shadeG.name = "g";
    shadeB.name = "b";
    shade_gray.name = "intensity";
    shadeR.values.reserve(rcvd_depth.rows()*rcvd_depth.cols());
    shadeG.values.reserve(rcvd_depth.rows()*rcvd_depth.cols());
    shadeB.values.reserve(rcvd_depth.rows()*rcvd_depth.cols());
    shade_gray.values.reserve(rcvd_depth.rows()*rcvd_depth.cols());


    //loop through each pixel
    float fx_inv = (float)1/fx;
    float fy_inv = (float)1/fy;
    for( int imx=0 ; imx<rcvd_depth.cols() ; imx++ )
    {
        for( int imy=0 ; imy<rcvd_depth.rows() ; imy++ )
        {

            /// [X Y Z]'  = depth * K_inv * [ imx imy 1.0 ]'
            float Z = (float)rcvd_dframe.at<uint16_t>(imy,imx);
            float X = (float)Z*(imx - cx)*fx_inv;
            float Y = (float)Z*(imy - cy)*fy_inv;

            geometry_msgs::Point32 pt;
            pt.x = X;
            pt.y = Y;
            pt.z = Z;



//            shadeR.values.push_back( (float)rcvd_red(imy,imx)/255. );
//            shadeG.values.push_back( (float)rcvd_green(imy,imx)/255. );
//            shadeB.values.push_back( (float)rcvd_blue(imy,imx)/255. );
            shade_gray.values.push_back( (float)rcvd_gray(imy,imx) );

            pcl_msg.points.push_back(pt);


        }
    }
//    pcl_msg.channels.push_back(shadeR);
//    pcl_msg.channels.push_back(shadeG);
//    pcl_msg.channels.push_back(shadeB);
    pcl_msg.channels.push_back(shade_gray);

    pub_pc.publish( pcl_msg );


}

void SolveDVO::publishBowl()
{
    sensor_msgs::PointCloud pcl_msg;
    pcl_msg.header.frame_id = "denseVO";
    pcl_msg.header.stamp = ros::Time::now();


    for( float x=-10 ;  x<10 ; x+=0.1 )
    {
        for( float y=-10 ; y<10 ; y+=0.1 )
        {
            float z = x*x + y*y;
            geometry_msgs::Point32 pt;
            pt.x = x/1000.;
            pt.y = y/1000.;
            pt.z = z/1000.;

            pcl_msg.points.push_back(pt);

        }
    }
    pub_pc.publish( pcl_msg );
}


/// @brief Display an Eigen::MatrixXd as an image (using opencv imshow())
void SolveDVO::imshowEigenImage(const char *winName, Eigen::MatrixXd eim)
{
    cv::Mat tmp, tmpuint;
    cv::eigen2cv( eim, tmp );
    tmp.convertTo(tmpuint, CV_8UC1);

    cv::imshow(winName, tmpuint );
}


/// @brief The event loop. Basically an ever running while with ros::spinOnce()
/// This is a re-implementation taking into care the memory scopes and also processing only points with higher image gradients
void SolveDVO::loop()
{
    ros::Rate rate(30);
    long int nFrame = 0;
    while( ros::ok() )
    {
        ros::spinOnce();
        if( !(this->isFrameAvailable) )
            continue;


        if( (nFrame % 60) == 0 )
        {
            //set this frame as reference frame
            setRefFrame();

            // compute jacobian

        }

        //set now frame
        setNowFrame();


        //cv::imshow( "im", this->rcvd_frame );
        //cv::imshow( "dim", this->rcvd_dframe );
        imshowEigenImage( "im", im );
        imshowEigenImage( "im_ref", im_r );


        publishCurrentPointCloud();
        //publishBowl();

        cv::waitKey(3);

        rate.sleep();
        nFrame++;
    }

}
